{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from PIL import Image\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PREPARAMOS LOS DATOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size =(256, 256)\n",
    "#modelo segmentacion\n",
    "path_modelo_segmentacion = \"./modeloPropio.h5\"\n",
    "modelo_propio = keras.models.load_model(\"modeloPropio.h5\")\n",
    "\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_image_for_segmentation(path,size=size,contrast=False,noise=False):\n",
    "    im = cv2.imread(path,0)\n",
    "    im = cv2.resize(im,size)\n",
    "\n",
    "    \n",
    "    #delete noise\n",
    "    if noise:\n",
    "        im = cv2.GaussianBlur(im,(5,5),0)\n",
    "\n",
    "    if contrast:\n",
    "        #increase contrast\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "        im = clahe.apply(im)\n",
    "    \n",
    "    \n",
    "    \n",
    "    im = cv2.cvtColor(im,cv2.COLOR_GRAY2RGB)\n",
    "    im = im.reshape((1,)+im.shape)\n",
    "    \n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_mask(i):\n",
    "    \"\"\"Quick utility to display a model's prediction.\"\"\"\n",
    "    mask = np.argmax(i, axis=-1)\n",
    "    mask = np.expand_dims(mask,axis=-1)\n",
    "    #if np.count_nonzero(mask == 0) < np.count_nonzero(mask == 1):\n",
    "    #    mask = np.invert(mask)\n",
    "    #mask = mask.astype(np.uint8)\n",
    "    mask = mask.reshape(size)\n",
    "    mask = mask*255\n",
    "    mask = mask.astype(np.uint8)\n",
    "\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def watershed(predicted_mask,img):\n",
    "    #convert to gray the image\n",
    "    #img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    kernel = np.ones((3,3),np.uint8)  \n",
    "    #opening\n",
    "    predicted_mask = cv2.morphologyEx(predicted_mask, cv2.MORPH_OPEN, kernel, iterations = 2)\n",
    "    #sure background area  \n",
    "    sure_bg = cv2.dilate(predicted_mask,kernel,iterations=10)\n",
    "\n",
    "    # Finding sure foreground area\n",
    "    dist_transform = cv2.distanceTransform(predicted_mask,cv2.DIST_L2,0)\n",
    "    ret, sure_fg = cv2.threshold(dist_transform,0.15*dist_transform.max(),255,0)\n",
    "\n",
    "    # Finding unknown region\n",
    "    sure_fg = np.uint8(sure_fg)\n",
    "    unknown = cv2.subtract(sure_bg,sure_fg)\n",
    "\n",
    "    # Marker labelling\n",
    "    ret, markers = cv2.connectedComponents(sure_fg)\n",
    "\n",
    "    # Add one to all labels so that sure background is not 0, but 1\n",
    "    markers = markers+1\n",
    "\n",
    "    # Now, mark the region of unknown with zero\n",
    "    markers[unknown==255] = 0\n",
    "\n",
    "    \n",
    "    markers = cv2.watershed(img,markers)\n",
    "    img[markers == -1] = [255,0,0]\n",
    "\n",
    "    #ALL THE PIXELS THAT ARE NOT 0 ARE 255\n",
    "    markers[markers != 1] = 255\n",
    "    markers[markers == 1] = 0\n",
    "    #put all the the pixels from the edges of the image to 255\n",
    "    #Para que al hacer el watershed se quede pegado a los bordes y al separar solo quede la zona de interes\n",
    "    #En el otro jupyter lo ponemos a 0 para evitar este efecto\n",
    "    markers[0,:] = 0\n",
    "    markers[-1,:] = 0\n",
    "    markers[:,0] = 0\n",
    "    markers[:,-1] = 0\n",
    "\n",
    "    markers = markers.astype(np.uint8)\n",
    "\n",
    "    return img,markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#directorio de las imagenes\n",
    "path = \"path_of_images\"\n",
    "\n",
    "#directorio de las mascaras finales\n",
    "save_path = \"path_of_final_masks\"\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as imag_save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove all directories from save_path\n",
    "for i in os.listdir(save_path):\n",
    "    #remove all files from the directory\n",
    "    for j in os.listdir(save_path+\"/\"+i):\n",
    "        os.remove(save_path+\"/\"+i+\"/\"+j)\n",
    "    os.rmdir(save_path+\"/\"+i)\n",
    "\n",
    "for i in os.listdir(path):\n",
    "    \n",
    "    #check if is a folder skip if not\n",
    "    if not os.path.isdir(path+\"/\"+i):\n",
    "        continue\n",
    "    \n",
    "    print(\"Analizando carpeta: \"+str(i))\n",
    "    os.mkdir(save_path+\"/\"+i)\n",
    "    #iterate over all images in the subfolder\n",
    "    for j in os.listdir(path+\"/\"+i):\n",
    "        img = prepare_image_for_segmentation(path+\"/\"+i+\"/\"+j,size=size,noise=True)\n",
    "        pred = modelo_propio.predict(img)\n",
    "        mask = obtain_mask(pred)\n",
    "        #invert mask if there are more 0 than 1\n",
    "        if np.count_nonzero(mask == 0) < np.count_nonzero(mask == 1):\n",
    "            mask = np.invert(mask)\n",
    "        \n",
    "        #watershed\n",
    "        mask = watershed(mask,img[0])[1]\n",
    "        imag_save.imsave(save_path+\"/\"+i+\"/\"+j, mask,cmap=\"gray\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separar_regiones(img,segmented=None,path=\"./prueba/\",j=0):\n",
    "    \n",
    "    if segmented is None:\n",
    "        segmented = img.copy()\n",
    "    #put all the the pixels from the edges of the image to 0\n",
    "    img[0,:] = 0\n",
    "    img[-1,:] = 0\n",
    "    img[:,0] = 0\n",
    "    img[:,-1] = 0\n",
    "    \n",
    "    _, thresh = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "\n",
    "    output = cv2.connectedComponentsWithStats(thresh, 4, cv2.CV_32S)\n",
    "    (numLabels, labels, stats, centroids) = output\n",
    "    \n",
    "    cell_areas = []\n",
    "\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "    \n",
    "\n",
    "    for i in range(0, numLabels):\n",
    "        # if this is the first component then we examine the\n",
    "        # *background* (typically we would just ignore this\n",
    "        # component in our loop)\n",
    "        if i == 0:\n",
    "            text = \"examining component {}/{} (background)\".format(\n",
    "                i + 1, numLabels)\n",
    "        # otherwise, we are examining an actual connected component\n",
    "        else:\n",
    "            text = \"examining component {}/{}\".format( i + 1, numLabels)\n",
    "        # print a status message update for the current connected\n",
    "        # component\n",
    "        print(\"[INFO] {}\".format(text))\n",
    "        # extract the connected component statistics and centroid\n",
    "        area = stats[i, cv2.CC_STAT_AREA]\n",
    "        x = stats[i, cv2.CC_STAT_LEFT]\n",
    "        y = stats[i, cv2.CC_STAT_TOP]\n",
    "        w = stats[i, cv2.CC_STAT_WIDTH]\n",
    "        h = stats[i, cv2.CC_STAT_HEIGHT]\n",
    "        margin = 20\n",
    "\n",
    "        componentMask = (labels == i).astype(\"uint8\") * 255\n",
    "        #crop the image\n",
    "        #componentMask = componentMask[y1:y2,x1:x2]\n",
    "        #check how centered is the centroid\n",
    "        if i!=0 and area > 50:        \n",
    "            #save the image\n",
    "            #check if the margin is out of bounds\n",
    "            if x-margin < 0:\n",
    "                x = margin\n",
    "            if y-margin < 0:\n",
    "                y = margin\n",
    "            if x+w+margin > segmented.shape[1]:\n",
    "                x = segmented.shape[1] - w - margin\n",
    "            if y+h+margin > segmented.shape[0]:\n",
    "                y = segmented.shape[0] - h - margin\n",
    "            \n",
    "            #Esto solo para el bounding box en nuestro caso al ser imagees tan zoomeadas no es necesario\n",
    "            #componentMask = componentMask[y-margin:y+h+margin,x-margin:x+w+margin]\n",
    "            \n",
    "            imag_save.imsave(path+str(j)+\"cell\"+str(i)+\".png\", componentMask,cmap=\"gray\")\n",
    "            \n",
    "\n",
    "    return np.array(cell_areas).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use separar regiones on all the images in the folder\n",
    "separated_path = \"path_of_separated_masks\"\n",
    "\n",
    "\n",
    "#remove all directories from save_path\n",
    "for i in os.listdir(separated_path):\n",
    "    #remove all files from the directory\n",
    "    for j in os.listdir(separated_path+\"/\"+i):\n",
    "        os.remove(separated_path+\"/\"+i+\"/\"+j)\n",
    "    os.rmdir(separated_path+\"/\"+i)\n",
    "\n",
    "for i in os.listdir(save_path):\n",
    "    if not os.path.isfile(separated_path+\"/\"+i):\n",
    "        os.mkdir(separated_path+\"/\"+i)\n",
    "    for j in os.listdir(save_path+\"/\"+i):\n",
    "        #read the image via numpy\n",
    "        \n",
    "        img = cv2.imread(save_path+\"/\"+i+\"/\"+j,0)\n",
    "        aux = separar_regiones(img,path=separated_path+\"/\"+i+\"/\",j=j)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PREPARACIÓN DE LOS DATOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sep_path = \"path_of_separated_masks\"\n",
    "dataset_path = \"path_of_separated_masks\"\n",
    "dirs = [\"bipiramides\",\"hexagonos\",\"circulos\",\"cuadrados\",\"rectangulos\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sep_path = \"path_of_separated_masks\"\n",
    "\n",
    "dirs = [\"bipiramides\",\"hexagonos\",\"circulos\",\"cuadrados\",\"rectangulos\"]\n",
    "#remove all directories from save_path\n",
    "for i in os.listdir(sep_path):\n",
    "    #remove all files from the directory\n",
    "    for j in os.listdir(sep_path+\"/\"+i):\n",
    "        os.remove(sep_path+\"/\"+i+\"/\"+j)\n",
    "    os.rmdir(sep_path+\"/\"+i)\n",
    "\n",
    "for i in dirs:\n",
    "    os.mkdir(sep_path+\"/\"+i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"path_of_separated_masks\"\n",
    "\n",
    "#remove all repeated images on the same folder\n",
    "for i in os.listdir(dataset_path):\n",
    "    for j in os.listdir(dataset_path+\"/\"+i):\n",
    "        for k in os.listdir(dataset_path+\"/\"+i):\n",
    "            if j!=k:\n",
    "                if os.path.isfile(dataset_path+\"/\"+i+\"/\"+j) and os.path.isfile(dataset_path+\"/\"+i+\"/\"+k):\n",
    "                    if np.array_equal(cv2.imread(dataset_path+\"/\"+i+\"/\"+j,0),cv2.imread(dataset_path+\"/\"+i+\"/\"+k,0)):\n",
    "                        os.remove(dataset_path+\"/\"+i+\"/\"+k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DO DATA AUGMENTATION\n",
    "dataset_path = \"path_of_separated_masks\"\n",
    "\n",
    "samples = 140\n",
    "\n",
    "#iterate over all the folders\n",
    "for i in os.listdir(dataset_path):\n",
    "    for j in os.listdir(dataset_path+\"/\"+i):\n",
    "        #remove all the files which contains flip in the name\n",
    "        if \"flip\" in j:\n",
    "            os.remove(dataset_path+\"/\"+i+\"/\"+j)\n",
    "\n",
    "\n",
    "#iterate over all the folders\n",
    "for i in os.listdir(dataset_path):\n",
    "    #if teh folder has less tan 100 images do data augmentation\n",
    "    if len(os.listdir(dataset_path+\"/\"+i)) < 140:\n",
    "        k=0\n",
    "\n",
    "        while len(os.listdir(dataset_path+\"/\"+i)) < 140:\n",
    "            \n",
    "        #iterate over all the images in the folder\n",
    "            for j in os.listdir(dataset_path+\"/\"+i):\n",
    "\n",
    "                #read the image\n",
    "                img = cv2.imread(dataset_path+\"/\"+i+\"/\"+j,0)\n",
    "                \n",
    "                angle = np.random.randint(0,360)\n",
    "                rows,cols = img.shape\n",
    "                M = cv2.getRotationMatrix2D((cols/2,rows/2),angle,1)\n",
    "                \n",
    "                img = cv2.warpAffine(img,M,(cols,rows))\n",
    "                #reflect the image\n",
    "                rep = None\n",
    "                ref = np.random.randint(0,3)\n",
    "                if ref == 1:\n",
    "                    img = cv2.flip(img,0)\n",
    "                elif ref == 2:\n",
    "                    img = cv2.flip(img,1)\n",
    "\n",
    "                #save the image\n",
    "                imag_save.imsave(dataset_path+\"/\"+i+\"/\"+str(k)+\"flip.png\", img,cmap=\"gray\")\n",
    "                k+=1\n",
    "                if len(os.listdir(dataset_path+\"/\"+i)) >= 140:\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOAD THE DATASET FROM THE DIRECTORY\n",
    "#load the images\n",
    "dataset_path = \"path_of_separated_masks\"\n",
    "#create the datagen with dtype uint8\n",
    "data_x = []\n",
    "data_y = []\n",
    "for i in os.listdir(dataset_path):\n",
    "    #check if is a folder skip if not\n",
    "    if not os.path.isdir(dataset_path+\"/\"+i):\n",
    "        continue\n",
    "    #iterate over all images in the subfolder\n",
    "    for j in os.listdir(dataset_path+\"/\"+i):\n",
    "        L = [0]*len(dirs)\n",
    "        #read the image witout resizing\n",
    "        img = cv2.imread(dataset_path+\"/\"+i+\"/\"+j,0)\n",
    "        \n",
    "        img = cv2.resize(img,(64,64))\n",
    "        #convert the image to a numpy array\n",
    "        img = np.array(img)\n",
    "        #append the image to the dataset\n",
    "        data_x.append(img)\n",
    "        #append the label to the dataset\n",
    "        L[dirs.index(i)] = 1\n",
    "        data_y.append(L)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = np.array(data_x)\n",
    "data_y = np.array(data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(size,dataset_path):\n",
    "    data_x = []\n",
    "    data_y = []\n",
    "    for i in os.listdir(dataset_path):\n",
    "        #check if is a folder skip if not\n",
    "        if not os.path.isdir(dataset_path+\"/\"+i):\n",
    "            continue\n",
    "        #iterate over all images in the subfolder\n",
    "        for j in os.listdir(dataset_path+\"/\"+i):\n",
    "            L = [0]*len(dirs)\n",
    "            #read the image witout resizing\n",
    "            img = cv2.imread(dataset_path+\"/\"+i+\"/\"+j,0)\n",
    "            \n",
    "            img = cv2.resize(img,size)\n",
    "            #convert the image to a numpy array\n",
    "            img = np.array(img)\n",
    "            #append the image to the dataset\n",
    "            data_x.append(img)\n",
    "            #append the label to the dataset\n",
    "            L[dirs.index(i)] = 1\n",
    "            data_y.append(L)\n",
    "    return np.array(data_x),np.array(data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_denso(input_shape):\n",
    "    \n",
    "    modelo_denso = tf.keras.Sequential()\n",
    "\n",
    "    modelo_denso.add(tf.keras.layers.Flatten(input_shape=input_shape))\n",
    "\n",
    "    modelo_denso.add(tf.keras.layers.Dense(512,activation='relu'))\n",
    "\n",
    "    modelo_denso.add(tf.keras.layers.Dense(256,activation='relu'))\n",
    "\n",
    "    modelo_denso.add(tf.keras.layers.Dense(256,activation='relu'))\n",
    "    \n",
    "    modelo_denso.add(tf.keras.layers.Dense(128,activation='relu'))\n",
    "\n",
    "    modelo_denso.add(tf.keras.layers.Dense(64,activation='relu'))\n",
    "    \n",
    "    modelo_denso.add(tf.keras.layers.Dense(32,activation='relu'))\n",
    "\n",
    "    modelo_denso.add(tf.keras.layers.Dense(5,activation='softmax'))\n",
    "\n",
    "\n",
    "    modelo_denso.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "    return modelo_denso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_denso_prueba_pardo(input_shape):\n",
    "    \n",
    "    modelo_denso = tf.keras.Sequential()\n",
    "\n",
    "    modelo_denso.add(tf.keras.layers.Flatten(input_shape=input_shape))\n",
    "\n",
    "    modelo_denso.add(tf.keras.layers.Dense(2048,activation='relu'))\n",
    "\n",
    "    modelo_denso.add(tf.keras.layers.Dense(512,activation='relu'))\n",
    "\n",
    "    #modelo_denso.add(tf.keras.layers.Dense(512,activation='relu'))\n",
    "\n",
    "    modelo_denso.add(tf.keras.layers.Dense(256,activation='relu'))\n",
    "\n",
    "    modelo_denso.add(tf.keras.layers.Dense(256,activation='relu'))\n",
    "\n",
    "    modelo_denso.add(tf.keras.layers.Dense(128,activation='relu'))\n",
    "\n",
    "    modelo_denso.add(tf.keras.layers.Dense(128,activation='relu'))\n",
    "\n",
    "    modelo_denso.add(tf.keras.layers.Dense(64,activation='relu'))\n",
    "\n",
    "    modelo_denso.add(tf.keras.layers.Dense(5,activation='softmax'))\n",
    "\n",
    "    modelo_denso.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "    return modelo_denso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"path_of_separated_masks\"\n",
    "testing_path = \"path_of_separated_TESTING_masks\"\n",
    "\n",
    "#remove all repeated images on the same folder para separar datos de entrenamiento y test\n",
    "for i in os.listdir(dataset_path):\n",
    "    for j in os.listdir(dataset_path+\"/\"+i):\n",
    "        for k in os.listdir(testing_path+\"/\"+i):\n",
    "            if j!=k:\n",
    "                if os.path.isfile(dataset_path+\"/\"+i+\"/\"+j) and os.path.isfile(testing_path+\"/\"+i+\"/\"+k):\n",
    "                    if np.array_equal(cv2.imread(dataset_path+\"/\"+i+\"/\"+j,0),cv2.imread(testing_path+\"/\"+i+\"/\"+k,0)):\n",
    "                        os.remove(dataset_path+\"/\"+i+\"/\"+k)\n",
    "\n",
    "#validation data\n",
    "validation_path = \"path_of_separated_validation_masks\"\n",
    "\n",
    "for i in os.listdir(dataset_path):\n",
    "    for j in os.listdir(dataset_path+\"/\"+i):\n",
    "        for k in os.listdir(validation_path+\"/\"+i):\n",
    "            if j!=k:\n",
    "                if os.path.isfile(dataset_path+\"/\"+i+\"/\"+j) and os.path.isfile(validation_path+\"/\"+i+\"/\"+k):\n",
    "                    if np.array_equal(cv2.imread(dataset_path+\"/\"+i+\"/\"+j,0),cv2.imread(validation_path+\"/\"+i+\"/\"+k,0)):\n",
    "                        os.remove(dataset_path+\"/\"+i+\"/\"+k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = (100,100)\n",
    "\n",
    "modelo = get_model_denso_prueba_pardo(size)\n",
    "\n",
    "data_x,data_y = prepare_data(size,\"path_of_separated_masks\")\n",
    "\n",
    "test_x,test_y = prepare_data(size,\"path_of_separated_test_masks\")\n",
    "\n",
    "val_x,val_y = prepare_data(size,\"path_of_separated_validation_masks\")\n",
    "\n",
    "#callback for saving the best model\n",
    "callbacks = [tf.keras.callbacks.ModelCheckpoint(filepath='./Recursos/Clasificacion/Modelos_Clasificacion/modelo_denso_prueba_variacion_pardo.h5',monitor='val_accuracy',save_best_only=True)]\n",
    "\n",
    "history = modelo.fit(data_x,data_y,epochs=50,batch_size=100,shuffle=True,verbose=1,validation_data=(test_x,test_y),callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the accuracy and loss\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['train','val'],loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['train','val'],loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_x,val_y = prepare_data(size,\"path_of_separated_validation_masks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sizes = [(i,i) for i in range(50,121,10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medidas = []\n",
    "\n",
    "\n",
    "for size in test_sizes:\n",
    "    print(\"Tamaño de la imagen: \",size)\n",
    "    accuracy = None\n",
    "    loss = None\n",
    "\n",
    "    for i in range(3):\n",
    "        modelo = get_model_denso_prueba_pardo(size)\n",
    "\n",
    "        train_x,train_y = prepare_data(size,\"path_of_separated_masks\")\n",
    "\n",
    "        val_x,val_y = prepare_data(size,\"path_of_separated_validation_masks\")\n",
    "\n",
    "        modelo.fit(train_x,train_y,epochs=50,shuffle=True,verbose=1)\n",
    "\n",
    "        aux_loss,aux_accuracy = modelo.evaluate(val_x,val_y,verbose=0)\n",
    "        if accuracy == None or aux_accuracy > accuracy:\n",
    "            accuracy = aux_accuracy\n",
    "            loss = aux_loss\n",
    "            modelo.save(\"./Recursos/Clasificacion/Modelos_Clasificacion/modelo_denso_prueba_pardo\"+ str(size[0])+\".h5\")\n",
    "            print(\"Loss: \",loss)\n",
    "            print(\"Accuracy: \",accuracy)\n",
    "\n",
    "    medidas.append((loss,accuracy))\n",
    "\n",
    "\n",
    "\n",
    "plt.plot([i[0] for i in test_sizes],[i[1] for i in medidas])\n",
    "plt.xlabel(\"Tamaño de la imagen\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot([i[0] for i in test_sizes],[i[0] for i in medidas])\n",
    "plt.xlabel(\"Tamaño de la imagen\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "plt.plot([i[0] for i in test_sizes],[i[1] for i in medidas])\n",
    "plt.xlabel(\"Tamaño de la imagen\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot([i[0] for i in test_sizes],[i[0] for i in medidas])\n",
    "plt.xlabel(\"Tamaño de la imagen\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
