{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a2140f8e",
   "metadata": {},
   "source": [
    "PARTE DE ENTRENAMIENTO DE LAS REDES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8ae6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18690239",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_image_to_segmentation(path,size=(160,160)):\n",
    "    #devuelve tensor de tamaño (1,160,160,3) para meter en la red\n",
    "    return np.array(load_img(path, target_size=size,color_mode=\"rgb\")).reshape((1,)+size+(3,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f30215",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_unet_collection import models,losses\n",
    "\n",
    "#model_Unet = models.unet_2d((256,256,3),filter_num=[64,128,256,512,1024],n_labels=2,stack_num_down=2,stack_num_up=2,activation='ReLU',output_activation='Sigmoid',batch_norm=True,pool=False,unpool=False,backbone='VGG16',weights='imagenet',freeze_backbone=True,freeze_batch_norm=True,name='unetlibreria')\n",
    "from keras_unet_collection import models,losses\n",
    "\n",
    "model_Unet = models.unet_2d((None,None,3),filter_num=[64,128,256,512,1024],n_labels=2,stack_num_down=2,stack_num_up=2,activation='ReLU',output_activation='Sigmoid',batch_norm=True,pool=False,unpool=False,weights='imagenet',freeze_backbone=False,freeze_batch_norm=False,name='unetlibreria')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68ee83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from IPython.display import Image, display\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from PIL import ImageOps, Image\n",
    "def obtain_mask(i):\n",
    "    \"\"\"Quick utility to display a model's prediction.\"\"\"\n",
    "    mask = np.argmax(i, axis=-1)\n",
    "    mask = np.expand_dims(mask,axis=-1)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f575646",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from IPython.display import Image, display\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from PIL import ImageOps, Image\n",
    "\n",
    "def display_mask(i):\n",
    "    \"\"\"Quick utility to display a model's prediction.\"\"\"\n",
    "    \n",
    "    mask = np.argmax(i, axis=-1)\n",
    "    mask = np.expand_dims(mask,axis=-1)\n",
    "    img = ImageOps.autocontrast(keras.preprocessing.image.array_to_img(mask))\n",
    "    display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae930d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Unet.compile(loss='binary_crossentropy',optimizer=keras.optimizers.Adam(learning_rate=1e-3),metrics=['accuracy',tf.keras.metrics.IoU(num_classes=2, target_class_ids=[0,1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b20fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet(img_size,num_classes):\n",
    "    \n",
    "    \n",
    "    #Input\n",
    "    layer = keras.Input(shape=img_size)\n",
    "    input_layer = layer \n",
    "    \n",
    "    output_block_layer = []\n",
    "    #Bloque de codificador\n",
    "    for i in [64,128,256,512]:\n",
    "        layer = layers.Conv2D(i,3,strides=1,padding=\"same\",activation=\"relu\")(layer)\n",
    "        layer = layers.BatchNormalization()(layer)\n",
    "        layer = layers.Conv2D(i,3,strides=1,padding=\"same\",activation=\"relu\")(layer)\n",
    "        layer = layers.BatchNormalization()(layer)\n",
    "        \n",
    "        #Guardo la capa para la parte de decodificacion\n",
    "        output_block_layer.append(layer)\n",
    "        \n",
    "        layer = layers.MaxPool2D(2)(layer)\n",
    "        layer = layers.Dropout(0.2)(layer)\n",
    "    \n",
    "    #Cuello de botella con 1024 filtros\n",
    "    layer = layers.Conv2D(1024,3,strides=1,padding=\"same\",activation=\"relu\")(layer)\n",
    "    layer = layers.BatchNormalization()(layer)\n",
    "    layer = layers.Conv2D(1024,3,strides=1,padding=\"same\",activation=\"relu\")(layer)\n",
    "    layer = layers.BatchNormalization()(layer)\n",
    "    \n",
    "    indice = 1\n",
    "    #Bloque decodificador\n",
    "    for i in [512,256,128,64]:\n",
    "        # upsample\n",
    "        layer = layers.Conv2DTranspose(i, 3, 2, padding=\"same\")(layer)\n",
    "        # concatenate\n",
    "        layer = layers.concatenate([layer, output_block_layer[len(output_block_layer)-indice]])\n",
    "        indice = indice+1\n",
    "        # dropout\n",
    "        layer = layers.Dropout(0.2)(layer)\n",
    "        # Conv2D twice with ReLU activation\n",
    "        layer = layers.Conv2D(i, 3, padding = \"same\", activation = \"relu\")(layer)\n",
    "        # Conv2D then ReLU activation\n",
    "        layer = layers.Conv2D(i, 3, padding = \"same\", activation = \"relu\")(layer)\n",
    "        \n",
    "    output = layers.Conv2D(num_classes,3, padding=\"same\", activation = \"softmax\")(layer)\n",
    "    \n",
    "    return tf.keras.Model(input_layer,output,name=\"U-Net\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26955065",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "input_dir = \"./TEM-Nano-Particle-Cell-Dataset-master/TEM-Nano-Particle-Cell-Dataset-master\"\n",
    "target_dir = \"./TEM-Nano-Particle-Cell-Dataset-master/TEM-Nano-Particle-Cell-Dataset-master/Validation\"\n",
    "img_size = (256,256)\n",
    "num_classes = 2\n",
    "batch_size = 32\n",
    "\n",
    "print(os.listdir(input_dir))\n",
    "\n",
    "print(os.listdir(target_dir))\n",
    "\n",
    "input_img_paths = [\n",
    "        os.path.join(input_dir, fname)\n",
    "        for fname in os.listdir(input_dir)\n",
    "        if fname.endswith(\".tif\")\n",
    "    ]\n",
    "target_img_paths = [\n",
    "        os.path.join(target_dir, fname)\n",
    "        for fname in os.listdir(target_dir)\n",
    "        if fname.endswith(\".tif\") and not fname.startswith(\".\")\n",
    "    ]\n",
    "#Para corregir donde se carga la primera imagen\n",
    "target_img_paths.insert(0,target_img_paths.pop(8))\n",
    "\n",
    "print(\"Number of samples:\", len(input_img_paths))\n",
    "\n",
    "for input_path, target_path in zip(input_img_paths[:10], target_img_paths[:10]):\n",
    "    print(input_path, \"|\", target_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7009b17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Display input image #7\n",
    "im = load_img(input_img_paths[0])\n",
    "display(im)\n",
    "# Display auto-contrast version of corresponding target (per-pixel categories)\n",
    "img = load_img(target_img_paths[0])\n",
    "display(img)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29c44e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prueba hecha en colab\n",
    "from PIL import Image\n",
    "def read_tif_img(path):\n",
    "    img = Image.open(path)\n",
    "    print(path)\n",
    "    img = img.resize((160,160))\n",
    "    img_rgb = img.convert('RGB')\n",
    "    imagen = np.array(img_rgb)\n",
    "    return imagen\n",
    "\n",
    "#pred = model.predict(imagen)\n",
    "\n",
    "#mask = np.argmax(pred[0,...,1:3], axis=-1)\n",
    "#mask = np.expand_dims(mask, axis=-1)\n",
    "#img = ImageOps.autocontrast(keras.preprocessing.image.array_to_img(mask))\n",
    "#display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637c9da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_preprocessing(tensor):\n",
    "    mask = np.argmax(tensor, axis=-1)\n",
    "    mask = np.expand_dims(mask,axis=-1)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de642e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "size = (256,256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d71a5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=45,     #Random rotation between 0 and 45\n",
    "        width_shift_range=0.2,   #% shift\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='wrap', cval=125)    #Also try nearest, constant, reflect, wrap\n",
    "\n",
    "maskgen = ImageDataGenerator(\n",
    "        rotation_range=45,     #Random rotation between 0 and 45\n",
    "        width_shift_range=0.2,   #% shift\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='wrap', cval=125)    #Also try nearest, constant, reflect, wrap\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb4a35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "def convert_to_grayscale_saved_augmentated_masks(directory):\n",
    "\tfor picture in os.listdir(directory):\n",
    "\t\tload_mask = np.array(load_img(directory + picture,color_mode=\"rgb\"))\n",
    "\t\tmask = np.argmax(load_mask, axis=-1)\n",
    "\t\tmask = np.expand_dims(mask,axis=-1)\n",
    "\t\timg = ImageOps.autocontrast(keras.preprocessing.image.array_to_img(mask))\n",
    "\t\timg.save(directory+picture.split('.')[0]+'.tif')\n",
    "\t\tos.remove(directory+picture)\n",
    "\n",
    "def change_format_augmentated_images(directory):\n",
    "\tfor picture in os.listdir(directory):\n",
    "\t\timg = np.array(load_img(directory + picture,color_mode=\"rgb\"))\n",
    "\t\timg = ImageOps.autocontrast(keras.preprocessing.image.array_to_img(img))\n",
    "\t\timg.save(directory+picture.split('.')[0]+'.tif')\n",
    "\t\tos.remove(directory+picture)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9ac478",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images = []\n",
    "\n",
    "all_masks = []\n",
    "\n",
    "for i in range(len(input_img_paths)):\n",
    "    all_images.append(np.array(load_img(input_img_paths[i], target_size=size,color_mode=\"rgb\")))\n",
    "    all_masks.append(np.array(load_img(target_img_paths[i], target_size=size,color_mode=\"grayscale\"))//255)\n",
    "\n",
    "all_images = np.array(all_images)\n",
    "all_masks = np.array(all_masks)\n",
    "all_masks_background_tags = (1-np.array(all_masks)).reshape((17,)+size)\n",
    "all_masks = np.stack((all_masks_background_tags,all_masks,np.zeros((17,)+size)),axis = -1)\n",
    "all_masks.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a39ea5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen.fit(all_images,augment=True,seed=109)\n",
    "maskgen.fit(all_masks,augment=True,seed=109)\n",
    "imagen_datagen = datagen.flow(all_images,seed=109,save_to_dir='./data/augmentation/images/')\n",
    "mask_datagen = maskgen.flow(all_masks,seed=109,save_to_dir='./data/augmentation/masks/')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8952044e",
   "metadata": {},
   "source": [
    "ANTES DE EJECUTAR LA SIGUIENTE CELDA VACIE LAS CARPETAS DE LAS FUNCIONES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb4132c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_augmentation = 20\n",
    "\n",
    "for i in range(num_augmentation):\n",
    "    imagen_datagen.next()\n",
    "    mask_datagen.next()\n",
    "\n",
    "\n",
    "\n",
    "convert_to_grayscale_saved_augmentated_masks('data/augmentation/masks/')\n",
    "change_format_augmentated_images('data/augmentation/images/')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6056b9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentatde_img_dir = 'data/augmentation/images/'\n",
    "augmentatde_maske_dir = 'data/augmentation/masks/'\n",
    "\n",
    "input_aug_img_paths = sorted([\n",
    "        os.path.join(augmentatde_img_dir, fname)\n",
    "        for fname in os.listdir(augmentatde_img_dir)\n",
    "        if fname.endswith(\".tif\")\n",
    "    ])\n",
    "target_aug_img_paths = sorted([\n",
    "        os.path.join(augmentatde_maske_dir, fname)\n",
    "        for fname in os.listdir(augmentatde_maske_dir)\n",
    "        if fname.endswith(\".tif\") and not fname.startswith(\".\")\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3cd2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(target_aug_img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f636b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "# Split our img paths into a training and a validation set\n",
    "val_samples = 50\n",
    "test_samples = 20\n",
    "random.Random(1337).shuffle(input_aug_img_paths)\n",
    "random.Random(1337).shuffle(target_aug_img_paths)\n",
    "\n",
    "train_input_img_paths = input_aug_img_paths[:-(val_samples + test_samples)]\n",
    "train_target_img_paths = target_aug_img_paths[:-(val_samples + test_samples)]\n",
    "val_input_img_paths = input_aug_img_paths[-(val_samples + test_samples):-test_samples]\n",
    "val_target_img_paths = target_aug_img_paths[-(val_samples + test_samples):-test_samples]\n",
    "test_input_img_path = input_aug_img_paths[-test_samples:]\n",
    "test_target_img_paths = target_aug_img_paths[-test_samples:]\n",
    "\n",
    "total_train_images = len(train_input_img_paths)\n",
    "print(len(train_input_img_paths),len(val_input_img_paths),len(test_input_img_path))\n",
    "# Instantiate data Sequences for each split\n",
    "train_x = []\n",
    "train_y = []\n",
    "for i in range(len(train_input_img_paths)):\n",
    "    train_x.append(np.array(load_img(train_input_img_paths[i], target_size=size,color_mode=\"rgb\")))\n",
    "    train_y.append(np.array(load_img(train_target_img_paths[i], target_size=size,color_mode=\"grayscale\"))//255)\n",
    "\n",
    "\n",
    "val_x = []\n",
    "val_y = []\n",
    "for i in range(len(val_input_img_paths)):\n",
    "    val_x.append(np.array(load_img(val_input_img_paths[i], target_size=size,color_mode=\"rgb\")))\n",
    "    val_y.append(np.array(load_img(val_target_img_paths[i], target_size=size,color_mode=\"grayscale\"))//255)\n",
    "\n",
    "test_x = []\n",
    "test_y = []\n",
    "for i in range(len(test_input_img_path)):\n",
    "    test_x.append(np.array(load_img(test_input_img_path[i], target_size=size,color_mode=\"rgb\")))\n",
    "    test_y.append(np.array(load_img(test_target_img_paths[i], target_size=size,color_mode=\"grayscale\"))//255)\n",
    "\n",
    "train_x = np.array(train_x)\n",
    "#train_x = np.stack((train_x,train_x,train_x),axis=-1)\n",
    "train_y = np.array(train_y).reshape((total_train_images,)+size)\n",
    "\n",
    "train_y_0 = (1-np.array(train_y)).reshape((total_train_images,)+size)\n",
    "#train_y_0 = (1-np.array(train_y)).reshape(32,160,160)\n",
    "#train_y = np.stack((train_y_0,train_y,np.zeros((total_train_images,)+size)),axis=-1).astype(\"uint8\")\n",
    "train_y = np.stack((train_y_0,train_y),axis=-1).astype(\"uint8\")\n",
    "\n",
    "test_x = np.array(test_x).reshape((test_samples,)+size+(3,))\n",
    "#test_x = np.stack((test_x,test_x,test_x),axis=-1)\n",
    "\n",
    "\n",
    "test_y_0 = (1-np.array(test_y)).reshape((test_samples,)+size)\n",
    "test_y = np.array(test_y).reshape((test_samples,)+size)\n",
    "\n",
    "test_y = np.stack((test_y_0,test_y),axis=-1).astype(\"uint8\")\n",
    "#test_y = np.stack((test_y_0,test_y,np.zeros((val_samples,)+size)),axis=-1).astype(\"uint8\")\n",
    "\n",
    "\n",
    "val_x = np.array(val_x).reshape((val_samples,)+size+(3,))\n",
    "#test_x = np.stack((test_x,test_x,test_x),axis=-1)\n",
    "\n",
    "\n",
    "val_y_0 = (1-np.array(val_y)).reshape((val_samples,)+size)\n",
    "val_y = np.array(val_y).reshape((val_samples,)+size)\n",
    "\n",
    "val_y = np.stack((val_y_0,val_y),axis=-1).astype(\"uint8\")\n",
    "#val_y = np.stack((val_y_0,val_y,np.zeros((val_samples,)+size)),axis=-1).astype(\"uint8\")\n",
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c58935",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6ba757",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entreno modelo libreria\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"entrenadoTL.h5\", save_best_only=True)\n",
    "]\n",
    "\n",
    "epochs = 25\n",
    "\n",
    "model_Unet.fit(train_x,train_y,batch_size=16,validation_data=(val_x,val_y),epochs=epochs,verbose=1,callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd91ec73",
   "metadata": {},
   "outputs": [],
   "source": [
    "ouputs = model_Unet.predict(test_x)\n",
    "ouputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c13acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model_Unet.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee624b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "modelo_cargado_oxford = keras.models.load_model(\"oxford_segmentation7032023.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d811fccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print((input_aug_img_paths))\n",
    "print((target_aug_img_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbe0970",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "# Preparación de datos\n",
    "# Split our img paths into a training and a validation set\n",
    "val_samples = 50\n",
    "test_samples = 20\n",
    "random.Random(1337).shuffle(input_aug_img_paths)\n",
    "random.Random(1337).shuffle(target_aug_img_paths)\n",
    "\n",
    "train_input_img_paths = input_aug_img_paths[:-(val_samples + test_samples)]\n",
    "train_target_img_paths = target_aug_img_paths[:-(val_samples + test_samples)]\n",
    "val_input_img_paths = input_aug_img_paths[-(val_samples + test_samples):-test_samples]\n",
    "val_target_img_paths = target_aug_img_paths[-(val_samples + test_samples):-test_samples]\n",
    "test_input_img_path = input_aug_img_paths[-test_samples:]\n",
    "test_target_img_paths = target_aug_img_paths[-test_samples:]\n",
    "\n",
    "print(test_input_img_path)\n",
    "\n",
    "total_train_images = len(train_input_img_paths)\n",
    "print(len(train_input_img_paths),len(val_input_img_paths),len(test_input_img_path))\n",
    "# Instantiate data Sequences for each split\n",
    "train_x = []\n",
    "train_y = []\n",
    "for i in range(len(train_input_img_paths)):\n",
    "    train_x.append(np.array(load_img(train_input_img_paths[i], target_size=size,color_mode=\"rgb\")))\n",
    "    train_y.append(np.array(load_img(train_target_img_paths[i], target_size=size,color_mode=\"grayscale\"))//255)\n",
    "\n",
    "\n",
    "val_x = []\n",
    "val_y = []\n",
    "for i in range(len(val_input_img_paths)):\n",
    "    val_x.append(np.array(load_img(val_input_img_paths[i], target_size=size,color_mode=\"rgb\")))\n",
    "    val_y.append(np.array(load_img(val_target_img_paths[i], target_size=size,color_mode=\"grayscale\"))//255)\n",
    "\n",
    "test_x = []\n",
    "test_y = []\n",
    "for i in range(len(test_input_img_path)):\n",
    "    test_x.append(np.array(load_img(test_input_img_path[i], target_size=size,color_mode=\"rgb\")))\n",
    "    test_y.append(np.array(load_img(test_target_img_paths[i], target_size=size,color_mode=\"grayscale\"))//255)\n",
    "\n",
    "train_x = np.array(train_x)\n",
    "#train_x = np.stack((train_x,train_x,train_x),axis=-1)\n",
    "#train_y = np.array(train_y).reshape(16,256,256)\n",
    "train_y = np.array(train_y).reshape((total_train_images,)+size)\n",
    "\n",
    "train_y_0 = (1-np.array(train_y)).reshape((total_train_images,)+size)\n",
    "#train_y_0 = (1-np.array(train_y)).reshape(32,160,160)\n",
    "train_y = np.stack((train_y_0,train_y,np.zeros((total_train_images,)+size)),axis=-1).astype(\"uint8\")\n",
    "#train_y = np.stack((train_y_0,train_y),axis=-1).astype(\"uint8\")\n",
    "\n",
    "test_x = np.array(test_x).reshape((test_samples,)+size+(3,))\n",
    "#test_x = np.stack((test_x,test_x,test_x),axis=-1)\n",
    "\n",
    "\n",
    "test_y_0 = (1-np.array(test_y)).reshape((test_samples,)+size)\n",
    "test_y = np.array(test_y).reshape((test_samples,)+size)\n",
    "\n",
    "#test_y = np.stack((test_y_0,test_y),axis=-1).astype(\"uint8\")\n",
    "test_y = np.stack((test_y_0,test_y,np.zeros((test_samples,)+size)),axis=-1).astype(\"uint8\")\n",
    "\n",
    "\n",
    "val_x = np.array(val_x).reshape((val_samples,)+size+(3,))\n",
    "#test_x = np.stack((test_x,test_x,test_x),axis=-1)\n",
    "\n",
    "\n",
    "val_y_0 = (1-np.array(val_y)).reshape((val_samples,)+size)\n",
    "val_y = np.array(val_y).reshape((val_samples,)+size)\n",
    "\n",
    "#val_y = np.stack((val_y_0,val_y),axis=-1).astype(\"uint8\")\n",
    "val_y = np.stack((val_y_0,val_y,np.zeros((val_samples,)+size)),axis=-1).astype(\"uint8\")\n",
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca78f1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entreno modelo oxford\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"modeloOxford.h5\", save_best_only=True)\n",
    "]\n",
    "modelo_cargado_oxford.compile(optimizer=\"adam\", \n",
    "                       loss=tf.keras.losses.categorical_crossentropy,#binary_focal_crossentropy\n",
    "                       metrics=[\"accuracy\",tf.keras.metrics.IoU(num_classes=2, target_class_ids=[1])])\n",
    "epochs = 25\n",
    "\n",
    "modelo_cargado_oxford.fit(train_x,train_y,batch_size=8,validation_data=(val_x,val_y),epochs=epochs,verbose=1,callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2b8079",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = display_mask(modelo_cargado_oxford.predict(test_x)[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b87d061",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(test_x[3])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcceae83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entreno modelo propio entrenado con dataset PETS\n",
    "\n",
    "modelo_cargado =  keras.models.load_model(\"UNET07032023.h5\")\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"modeloPropio.h5\", save_best_only=True)\n",
    "]\n",
    "modelo_cargado.compile(optimizer=\"adam\", \n",
    "                       loss=tf.keras.losses.categorical_crossentropy,#binary_focal_crossentropy\n",
    "                       metrics=[\"accuracy\",tf.keras.metrics.IoU(num_classes=2, target_class_ids=[1])])\n",
    "epochs = 25\n",
    "\n",
    "modelo_cargado.fit(train_x,train_y,batch_size=16,validation_data=(val_x,val_y),epochs=epochs,verbose=1,callbacks=callbacks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "069005490ad46b5711cb48874946336380c77677d23ab57c7c9127102a90fd02"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
